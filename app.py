import streamlit as st
import fitz  # PyMuPDF
import os
import shutil
import zipfile
import pandas as pd
import io
import aiohttp
import asyncio
import concurrent.futures
import base64
import tiktoken
import streamlit_shadcn_ui as ui
import streamlit.components.v1 as components

from openai import OpenAI
from google.cloud import vision
from py_currency_converter import convert

with st.sidebar:
    st.markdown(
        """
        <style>
        .stTextInput, .stTextArea {
            box-shadow: 2px 2px 2px rgba(0, 0, 0, 0.1);
            border-radius: 5px;
            border: none;
        }
        [data-testid='stFileUploader'] {
            width: 90%;
        }
        [data-testid='stFileUploader'] section button {
            background-color: black !important;
            color: white !important;
            border-radius: 5px;
        }
        [data-testid='stFileUploader'] section {
            background: black!important;
            color: black !important;
            padding: 0;
            float: left;
        }
        [data-testid='stFileUploader'] section > input + div {
            display: none;
        }
        </style>
        """,
        unsafe_allow_html=True
    )

def create_directories():
    os.makedirs("static", exist_ok=True)
    os.makedirs("temp", exist_ok=True)

def clear_directory(directory):
    if os.path.exists(directory):
        shutil.rmtree(directory)
    os.makedirs(directory, exist_ok=True)

# å®šç¾©åœ¨PDFä¸­æœå°‹æ–‡æœ¬ä¸¦è¿”å›é ç¢¼å’ŒçŸ©å½¢å€åŸŸçš„å‡½æ•¸
def search_pdf(file, text):
    doc = fitz.open(file)
    res = []
    for i, page in enumerate(doc):
        insts = page.search_for(text)
        for inst in insts:
            res.append((i + 1, inst))
    return res

# å®šç¾©æå–é é¢ç‰¹å®šå€åŸŸä½œç‚ºåœ–ç‰‡ï¼ˆå…¨é å¯¬åº¦ï¼‰ï¼Œé«˜è§£æåº¦çš„å‡½æ•¸
def extract_img(file, page_num, rect, out_dir, h, z=6.0, offset=0):
    doc = fitz.open(file)
    page = doc.load_page(page_num - 1)
    mat = fitz.Matrix(z, z)
    pw = page.rect.width
    clip = fitz.Rect(0, rect.y0 + offset, pw, rect.y0 + offset + h)
    pix = page.get_pixmap(matrix=mat, clip=clip)
    img_path = os.path.join(out_dir, f"page_{page_num}.png")
    pix.save(img_path)
    return img_path

# å®šç¾©é‡å‘½ååœ–ç‰‡æ–‡ä»¶çš„å‡½æ•¸
def rename_img(old_p, new_name):
    new_p = os.path.join(os.path.dirname(old_p), new_name)
    os.rename(old_p, new_p)
    return new_p

# å®šç¾©æœå°‹æ–‡æœ¬ä¸¦æå–å°æ‡‰å€åŸŸä½œç‚ºå…¨é å¯¬åº¦åœ–ç‰‡çš„å‡½æ•¸
def search_extract_img(file, text, out_dir, h, offset=0):
    res = search_pdf(file, text)
    if res:
        page_num, rect = res[0]
        img_p = extract_img(file, page_num, rect, out_dir, h=h, offset=offset)
        new_img_p = rename_img(img_p, f"{text}.png")
        return page_num, new_img_p
    return None, None

# å®šç¾©æ–‡æœ¬æ ¼å¼åŒ–å‡½æ•¸
def format_text(text):
    lines = text.split('\n\n')
    formatted_lines = [line.strip() for line in lines if line.strip()]
    return '\n'.join(formatted_lines)

# ä½¿ç”¨ Google Vision API æå–æ–‡æœ¬
def extract_text_from_image(img_path):
    client = vision.ImageAnnotatorClient()
    with io.open(img_path, 'rb') as image_file:
        content = image_file.read()
    image = vision.Image(content=content)
    response = client.text_detection(image=image)
    texts = response.text_annotations
    if texts:
        return texts[0].description
    return ""

def trigger_download(zip_buffer, filename):
    b64 = base64.b64encode(zip_buffer).decode()
    components.html(f"""
        <html>
        <head>
        <script type="text/javascript">
            function downloadURI(uri, name) {{
                var link = document.createElement("a");
                link.href = uri;
                link.download = name;
                document.body.appendChild(link);
                link.click();
                document.body.removeChild(link);
            }}
            window.onload = function() {{
                var link = document.createElement("a");
                link.href = "data:application/zip;base64,{b64}";
                link.download = "{filename}";
                link.click();
            }}
        </script>
        </head>
        </html>
    """, height=0)

@st.cache_data
def get_upload_files():
    return {"pdf": None, "data": None, "json": None, "api_key": "", "height": "", "symbol": "", "height_map_str": "", "height_map": {}, "user_input": ""}

uploaded_files = get_upload_files()

def update_uploaded_files():
    if 'pdf_file_uploader' in st.session_state:
        uploaded_files["pdf"] = st.session_state.pdf_file_uploader
    if 'data_file_uploader' in st.session_state:
        uploaded_files["data"] = st.session_state.data_file_uploader
    if 'json_file_uploader' in st.session_state:
        uploaded_files["json"] = st.session_state.json_file_uploader
    if 'api_key' in st.session_state:
        uploaded_files["api_key"] = st.session_state.api_key
    if 'height_input' in st.session_state:
        uploaded_files["height"] = st.session_state.height_input
    if 'symbol_input' in st.session_state:
        uploaded_files["symbol"] = st.session_state.symbol_input
    if 'height_map_str_input' in st.session_state:
        uploaded_files["height_map_str"] = st.session_state.height_map_str_input
        height_map = {}
        for item in uploaded_files["height_map_str"].split("\n"):
            if ":" in item:
                k, v = item.split(":")
                height_map[int(k.strip())] = int(v.strip())
        uploaded_files["height_map"] = height_map
    if 'user_input_input' in st.session_state:
        uploaded_files["user_input"] = st.session_state.user_input_input

# åˆå§‹åŒ– session state è®Šæ•¸
if 'zip_buffer' not in st.session_state:
    st.session_state.zip_buffer = None
if 'zip_file_ready' not in st.session_state:
    st.session_state.zip_file_ready = False
if 'df_text' not in st.session_state:
    st.session_state.df_text = pd.DataFrame()
if 'task_completed' not in st.session_state:
    st.session_state.task_completed = False
if 'download_triggered' not in st.session_state:
    st.session_state.download_triggered = False
if 'total_input_tokens' not in st.session_state:
    st.session_state.total_input_tokens = 0
if 'total_output_tokens' not in st.session_state:
    st.session_state.total_output_tokens = 0

async def fetch_gpt_response(session, api_key, text, prompt):
    url = "https://api.openai.com/v1/chat/completions"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }
    payload = {
        "model": "gpt-4o-mini",
        "messages": [{"role": "user", "content": prompt.format(text)}]
    }
    async with session.post(url, headers=headers, json=payload) as response:
        return await response.json()

async def process_texts(api_key, texts, prompt, batch_size=10):
    async with aiohttp.ClientSession() as session:
        tasks = []
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            tasks.extend([fetch_gpt_response(session, api_key, text, prompt) for text in batch])
            if tasks:
                results = await asyncio.gather(*tasks)
                for result, text in zip(results, batch):
                    organized_text = result['choices'][0]['message']['content']
                    formatted_text = format_text(organized_text)
                    yield {"è²¨è™Ÿ": text, "æ–‡æ¡ˆ": formatted_text}

def search_and_zip_case1(file, texts, h, out_dir, zipf, api_key, prompt):
    total_files = len(texts)
    progress_bar = st.progress(0)
    progress_text = st.empty()
    progress_text.text("æº–å‚™è¼‰å…¥PDFèˆ‡CSVæ–‡ä»¶")

    for i, text in enumerate(texts):
        page_num, img_p = search_extract_img(file, text, out_dir, h=h)
        if img_p:
            zipf.write(img_p, os.path.basename(img_p))
        # æ›´æ–°é€²åº¦æ¢
        progress = (i + 1) / total_files
        progress_bar.progress(progress)
        progress_text.text(f"æ­£åœ¨æ“·å–åœ–ç‰‡: {text} ({i + 1}/{total_files})")
    progress_bar.empty()
    progress_text.empty()

# å®šç¾©æœå°‹å¤šå€‹æ–‡æœ¬ä¸¦å‰µå»ºå£“ç¸®æ–‡ä»¶çš„å‡½æ•¸ï¼Œæƒ…æ³2
def search_and_zip_case2(file, texts, symbol, height_map, out_dir, zipf):
    total_files = len(texts)
    progress_bar = st.progress(0)
    progress_text = st.empty()
    progress_text.text("æº–å‚™è¼‰å…¥PDFèˆ‡CSVæ–‡ä»¶")
    
    for i, text in enumerate(texts):
        res = search_pdf(file, text)
        if res:
            page_num, rect = res[0]
            doc = fitz.open(file)
            page = doc.load_page(page_num - 1)
            symbol_count = len(page.search_for(symbol))
            height = height_map.get(symbol_count, 240)
            img_p = extract_img(file, page_num, rect, out_dir, h=height, offset=-10)
            new_img_p = rename_img(img_p, f"{text}.png")
            zipf.write(new_img_p, os.path.basename(new_img_p))
        # æ›´æ–°é€²åº¦æ¢
        progress = (i + 1) / total_files
        progress_bar.progress(progress)
        progress_text.text(f"æ­£åœ¨æ“·å–åœ–ç‰‡: {text} ({i + 1}/{total_files})")
    progress_bar.empty()
    progress_text.empty()

def update_height():
    if st.session_state['height'] != st.session_state['height_input']:
        st.session_state['height'] = st.session_state['height_input']

def update_user_input():
    if st.session_state['user_input'] != st.session_state['user_input_input']:
        st.session_state['user_input'] = st.session_state['user_input_input']

def update_symbol():
    if st.session_state['symbol'] != st.session_state['symbol_input']:
        st.session_state['symbol'] = st.session_state['symbol_input']

def update_height_map_str():
    if st.session_state['height_map_str'] != st.session_state['height_map_str_input']:
        st.session_state['height_map_str'] = st.session_state['height_map_str_input']
        height_map = {}
        for item in st.session_state['height_map_str'].split("\n"):
            if ":" in item:
                k, v = item.split(":")
                height_map[int(k.strip())] = int(v.strip())
        st.session_state['height_map'] = height_map

def main():
    create_directories() 
    option = ui.tabs(options=["æ¯é å•†å“æ•¸ã€Œå›ºå®šã€çš„æƒ…å½¢", "æ¯é å•†å“æ•¸ã€Œä¸å›ºå®šã€çš„æƒ…å½¢"], default_value="æ¯é å•†å“æ•¸ã€Œå›ºå®šã€çš„æƒ…å½¢")

    with st.sidebar:
        st.image("Image/91APP_logo.png")
        with st.expander("æ–‡ä»¶ä¸Šå‚³"):
            pdf_file = st.file_uploader("ä¸Šå‚³ PDF", type=["pdf"], key="pdf_file_uploader")
            data_file = st.file_uploader("ä¸Šå‚³ CSV æˆ– XLSX", type=["csv", "xlsx"], key="data_file_uploader")
            json_file = st.file_uploader("ä¸Šå‚³ Google Cloud æ†‘è­‰", type=["json"], key="json_file_uploader")
        st.write("\n")
        api_key = st.text_input("è¼¸å…¥ OpenAI API Key", type="password")

    # å°‡å·²ä¸Šå‚³çš„æ–‡ä»¶å­˜å…¥ session state
    if pdf_file:
        st.session_state.pdf_file = pdf_file
    if data_file:
        st.session_state.data_file = data_file
    if json_file:
        st.session_state.json_file = json_file
    if api_key:
        st.session_state.api_key = api_key

    # å¾ session state ä¸­ç²å–æ–‡ä»¶
    pdf_file = st.session_state.pdf_file
    data_file = st.session_state.data_file
    json_file = st.session_state.json_file
    api_key = st.session_state.api_key

    if json_file:
        temp_json_path = os.path.join("temp", json_file.name)
        with open(temp_json_path, "wb") as f:
            f.write(json_file.getbuffer())
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = temp_json_path

    if option == "æ¯é å•†å“æ•¸ã€Œå›ºå®šã€çš„æƒ…å½¢":
        height = st.text_input("æŒ‡å®šæˆªåœ–é«˜åº¦ (px)", placeholder="ä¾‹å¦‚ï¼š255", value=st.session_state.height, key='height_input', on_change=update_height, help="å¦‚ä½•æ‰¾åˆ°æˆªåœ–é«˜åº¦ï¼Ÿ\n\n1.æˆªä¸€å¼µæƒ³è¦çš„åœ–ç‰‡ç¯„åœ \n 2.ä¸Šå‚³Photoshopï¼ŒæŸ¥çœ‹å·¦å´çš„åœ–ç‰‡é«˜åº¦")
        user_input = st.text_area("çµ¦ ChatGPT çš„ Prompt", height=300, value=st.session_state.user_input, key='user_input_input', on_change=update_user_input)
    else:
        symbol = st.text_input("ç”¨ä¾†åˆ¤æ–·æˆªåœ–é«˜åº¦çš„ç¬¦è™Ÿæˆ–æ–‡å­—", placeholder="ä¾‹å¦‚ï¼š$", value=st.session_state.symbol, key='symbol_input', on_change=update_symbol)
        col1, col2 = st.columns([1,1.9])
        height_map_str = col1.text_area("å°æ‡‰çš„æˆªåœ–é«˜åº¦ï¼ˆpxï¼‰", placeholder="æ•¸é‡ï¼šé«˜åº¦ï¼ˆç”¨æ›è¡Œåˆ†éš”ï¼‰\n----------------------------------------\n2:350\n3:240", height=300, value=st.session_state.height_map_str, key='height_map_str_input', on_change=update_height_map_str, help="å¦‚ä½•æ‰¾åˆ°æˆªåœ–é«˜åº¦ï¼Ÿ\n\n1.æˆªä¸€å¼µæƒ³è¦çš„åœ–ç‰‡ç¯„åœ \n 2.ä¸Šå‚³Photoshopï¼ŒæŸ¥çœ‹å·¦å´çš„åœ–ç‰‡é«˜åº¦")
        user_input = col2.text_area("çµ¦ ChatGPT çš„ Prompt", height=300, value=st.session_state.user_input, key='user_input_input', on_change=update_user_input)
    
    def organize_text_with_gpt(text, api_key):
        client = OpenAI(api_key=api_key)
        prompt = f"'''{text} '''{st.session_state.user_input}"
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "user", "content": prompt}
            ],
        )
        
        # ä½¿ç”¨ tiktoken è¨ˆç®— tokens æ•¸é‡
        encoding = tiktoken.encoding_for_model("gpt-4")
        input_tokens = len(encoding.encode(prompt))
        output_tokens = len(encoding.encode(response.choices[0].message.content))
        
        # å°‡ tokens è¨ˆæ•¸å­˜å…¥ session_state
        st.session_state.total_input_tokens += input_tokens
        st.session_state.total_output_tokens += output_tokens
        
        return response.choices[0].message.content
    
    def check_required_fields():
        missing_fields = []
        if not pdf_file:
            missing_fields.append("PDF")
        if not data_file:
            missing_fields.append("CSV æˆ– XLSX")
        if not json_file:
            missing_fields.append("Google Cloud æ†‘è­‰")
        if not api_key:
            missing_fields.append("OpenAI API Key")
        if not st.session_state.user_input:
            missing_fields.append("çµ¦ ChatGPT çš„ Prompt")
        if option == "æ¯é å•†å“æ•¸ã€Œå›ºå®šã€çš„æƒ…å½¢" and not st.session_state.height:
            missing_fields.append("æŒ‡å®šæˆªåœ–é«˜åº¦")
        if option == "æ¯é å•†å“æ•¸ã€Œä¸å›ºå®šã€çš„æƒ…å½¢":
            if not st.session_state.symbol:
                missing_fields.append("ç”¨ä¾†åˆ¤æ–·æˆªåœ–é«˜åº¦çš„ç¬¦è™Ÿæˆ–æ–‡å­—")
            if not st.session_state.height_map:
                missing_fields.append("å°æ‡‰çš„æˆªåœ–é«˜åº¦")
        return missing_fields
    
    # æª¢æŸ¥æ‰€æœ‰å¿…éœ€å­—æ®µæ˜¯å¦å·²å¡«å¯«
    missing_fields = check_required_fields()
    
    if ui.button("é–‹å§‹åŸ·è¡Œ", key="run_btn"):
        if missing_fields:
            st.warning("è«‹ä¸Šå‚³æˆ–è¼¸å…¥ä»¥ä¸‹å¿…éœ€çš„é …ç›®ï¼š{}".format("ã€".join(missing_fields)))
        else:
            # é‡ç½®è¼¸å…¥å’Œè¼¸å‡º tokens è¨ˆæ•¸
            st.session_state.total_input_tokens = 0
            st.session_state.total_output_tokens = 0

            # æ¸…é™¤ä¹‹å‰çš„é¡¯ç¤ºå…§å®¹
            st.session_state.task_completed = False
            st.session_state.download_triggered = False
            st.session_state.zip_buffer = None
            st.session_state.zip_file_ready = False
            st.session_state.df_text = pd.DataFrame()

            temp_dir = "temp"
            output_dir = os.path.join(temp_dir, "output")
            clear_directory(output_dir)  

            pdf_path = os.path.join(temp_dir, uploaded_files["pdf"].name)
            with open(pdf_path, "wb") as f:
                f.write(uploaded_files["pdf"].getbuffer())

            data_path = os.path.join(temp_dir, uploaded_files["data"].name)
            with open(data_path, "wb") as f:
                f.write(uploaded_files["data"].getbuffer())

            try:
                if uploaded_files["data"].name.endswith('.csv'):
                    df = pd.read_csv(data_path, encoding='utf-8')
                else:
                    df = pd.read_excel(data_path, engine='openpyxl')
            except UnicodeDecodeError:
                if uploaded_files["data"].name.endswith('.csv'):
                    df = pd.read_csv(data_path, encoding='latin1')
                else:
                    df = pd.read_excel(data_path, engine='openpyxl')

            texts = df.iloc[:, 0].tolist()

            zip_buffer = io.BytesIO()
            with zipfile.ZipFile(zip_buffer, 'w') as zipf:
                if option == "æ¯é å•†å“æ•¸ã€Œå›ºå®šã€çš„æƒ…å½¢":
                    search_and_zip_case1(pdf_path, texts, int(uploaded_files["height"]), output_dir, zipf, uploaded_files["api_key"], uploaded_files["user_input"])
                else:
                    search_and_zip_case2(pdf_path, texts, uploaded_files["symbol"], uploaded_files["height_map"], output_dir, zipf)

                image_files = [f for f in os.listdir(output_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]
                data = []
                total_files = len(image_files)

                progress_bar = st.progress(0)
                progress_text = st.empty()
                progress_text.text("æº–å‚™è¼‰å…¥æˆªåœ–")

                with concurrent.futures.ThreadPoolExecutor() as executor:
                    futures = {executor.submit(extract_text_from_image, os.path.join(output_dir, image_file)): image_file for image_file in image_files}
                    for future in concurrent.futures.as_completed(futures):
                        image_file = futures[future]
                        try:
                            text = future.result()
                            organized_text = organize_text_with_gpt(text, uploaded_files["api_key"])
                            formatted_text = format_text(organized_text)
                            data.append({"è²¨è™Ÿ": os.path.splitext(image_file)[0], "åœ–ç‰‡å…§å®¹": text, "æ–‡æ¡ˆ": formatted_text})
                        except Exception as exc:
                            print(f'{image_file} generated an exception: {exc}')

                        progress = len(data) / total_files
                        progress_bar.progress(progress)
                        progress_text.text(f"æ­£åœ¨æå–åœ–ç‰‡æ–‡å­—èˆ‡æ’°å¯«æ–‡æ¡ˆ: {image_file} ({len(data)}/{total_files})")

                progress_bar.empty()
                progress_text.empty()

                df_text = pd.DataFrame(data)
                csv_buffer = io.StringIO()
                df_text.to_csv(csv_buffer, index=False, encoding='utf-8-sig')  
                csv_data = csv_buffer.getvalue().encode('utf-8-sig')

                zipf.writestr("ocr_output.csv", csv_data)

            zip_buffer.seek(0)

            st.session_state.zip_buffer = zip_buffer.getvalue()
            st.session_state.zip_file_ready = True
            st.session_state.df_text = df_text
            st.session_state.task_completed = True

    if st.session_state.task_completed and st.session_state.zip_file_ready and not st.session_state.download_triggered:
        def usd_to_twd(usd_amount):
            result = convert(base='USD', amount=usd_amount, to=['TWD'])
            return result['TWD']

        input_cost = st.session_state.total_input_tokens / 1_000_000 * 0.15
        output_cost = st.session_state.total_output_tokens / 1_000_000 * 0.60
        total_cost_usd = input_cost + output_cost
        total_cost_twd = usd_to_twd(total_cost_usd)
            
        st.toast("åŸ·è¡Œå®Œæˆ ğŸ¥³ æª”æ¡ˆå·²è‡ªå‹•ä¸‹è¼‰è‡³æ‚¨çš„é›»è…¦")
        st.divider()
        col1,col2,col3 =st.columns(3)
        with col1:
            ui.metric_card(title="Input Tokens", content=f"{st.session_state.total_input_tokens} å€‹", description="US$0.15 / æ¯ç™¾è¬å€‹Tokens", key="card1")
        with col2:
            ui.metric_card(title="Output Tokens", content=f"{st.session_state.total_output_tokens} å€‹", description="US$0.60 / æ¯ç™¾è¬å€‹Tokens", key="card2")
        with col3:
            ui.metric_card(title="æœ¬æ¬¡åŸ·è¡Œè²»ç”¨", content=f"${total_cost_twd:.2f} å°å¹£", description="æ ¹æ“šå³æ™‚åŒ¯ç‡", key="card3")
            
        with st.container(height=400):
            st.write("##### æˆæœé è¦½")
            ui.table(st.session_state.df_text)
        trigger_download(st.session_state.zip_buffer, "output.zip")
        st.session_state.download_triggered = True

if __name__ == "__main__":
    main()
