import streamlit as st
import fitz  # PyMuPDF
import os
import shutil
import zipfile
import pandas as pd
import io
import aiohttp
import asyncio
import concurrent.futures
import base64
import tiktoken
import streamlit_shadcn_ui as ui
import streamlit.components.v1 as components

from openai import OpenAI
from google.cloud import vision
from py_currency_converter import convert
from streamlit_extras.stylable_container import stylable_container
from streamlit_option_menu import option_menu

with st.sidebar:
    st.markdown(
        """
        <style>
        .centered {
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100%;
            text-align: center;
        }
        [data-testid='stFileUploader'] section button {
            background: transparent !important;
            color: #46474A !important;
            border-radius: 5px;
            border: none;
            display: block;
            margin: 0 auto;
        }
        [data-testid='stFileUploader'] section {
            background: linear-gradient(-135deg, #FFFFFF 0%, #ECECEC 80%, #D4D4D4 80%, #ECECEC 80%)!important;
            color: black !important;
            padding: 0;
        ;
        }
        [data-testid='stFileUploader'] section > input + div {
            display: none;
        }
        [data-testid=stSidebar] {
            background: #F9F9F9;
        }
        </style>
        """,
        unsafe_allow_html=True
    )
st.markdown('<div class="centered"><h2>å•†é‹  PDFæˆªåœ–èˆ‡AIæ–‡æ¡ˆç”Ÿæˆå·¥å…·</h2></div>', unsafe_allow_html=True)
st.write("\n")

def create_directories():
    os.makedirs("static", exist_ok=True)
    os.makedirs("temp", exist_ok=True)

def clear_directory(directory):
    if os.path.exists(directory):
        shutil.rmtree(directory)
    os.makedirs(directory, exist_ok=True)

# å®šç¾©åœ¨PDFä¸­æœå°‹æ–‡æœ¬ä¸¦è¿”å›é ç¢¼å’ŒçŸ©å½¢å€åŸŸçš„å‡½æ•¸
def search_pdf(file, text):
    doc = fitz.open(file)
    res = []
    for i, page in enumerate(doc):
        insts = page.search_for(text)
        for inst in insts:
            res.append((i + 1, inst))
    return res

# å®šç¾©æå–é é¢ç‰¹å®šå€åŸŸä½œç‚ºåœ–ç‰‡ï¼ˆå…¨é å¯¬åº¦ï¼‰ï¼Œé«˜è§£æåº¦çš„å‡½æ•¸
def extract_img(file, page_num, rect, out_dir, h, z=6.0, offset=0):
    doc = fitz.open(file)
    page = doc.load_page(page_num - 1)
    mat = fitz.Matrix(z, z)
    pw = page.rect.width
    clip = fitz.Rect(0, rect.y0 + offset, pw, rect.y0 + offset + h)
    pix = page.get_pixmap(matrix=mat, clip=clip)
    img_path = os.path.join(out_dir, f"page_{page_num}.png")
    pix.save(img_path)
    return img_path

# å®šç¾©é‡å‘½ååœ–ç‰‡æ–‡ä»¶çš„å‡½æ•¸
def rename_img(old_p, new_name):
    new_p = os.path.join(os.path.dirname(old_p), new_name)
    os.rename(old_p, new_p)
    return new_p

# å®šç¾©æœå°‹æ–‡æœ¬ä¸¦æå–å°æ‡‰å€åŸŸä½œç‚ºå…¨é å¯¬åº¦åœ–ç‰‡çš„å‡½æ•¸
def search_extract_img(file, text, out_dir, h, offset=0):
    res = search_pdf(file, text)
    if res:
        page_num, rect = res[0]
        img_p = extract_img(file, page_num, rect, out_dir, h=h, offset=offset)
        new_img_p = rename_img(img_p, f"{text}.png")
        return page_num, new_img_p
    return None, None

# å®šç¾©æ–‡æœ¬æ ¼å¼åŒ–å‡½æ•¸
def format_text(text):
    lines = text.split('\n\n')
    formatted_lines = [line.strip() for line in lines if line.strip()]
    return '\n'.join(formatted_lines)

# ä½¿ç”¨ Google Vision API æå–æ–‡æœ¬
def extract_text_from_image(img_path):
    client = vision.ImageAnnotatorClient()
    with io.open(img_path, 'rb') as image_file:
        content = image_file.read()
    image = vision.Image(content=content)
    response = client.text_detection(image=image)
    texts = response.text_annotations
    if texts:
        return texts[0].description
    return ""

def trigger_download(zip_buffer, filename):
    b64 = base64.b64encode(zip_buffer).decode()
    components.html(f"""
        <html>
        <head>
        <script type="text/javascript">
            function downloadURI(uri, name) {{
                var link = document.createElement("a");
                link.href = uri;
                link.download = name;
                document.body.appendChild(link);
                link.click();
                document.body.removeChild(link);
            }}
            window.onload = function() {{
                var link = document.createElement("a");
                link.href = "data:application/zip;base64,{b64}";
                link.download = "{filename}";
                link.click();
            }}
        </script>
        </head>
        </html>
    """, height=0)

# åˆå§‹åŒ– session state è®Šæ•¸
if 'zip_buffer' not in st.session_state:
    st.session_state.zip_buffer = None
if 'zip_file_ready' not in st.session_state:
    st.session_state.zip_file_ready = False
if 'df_text' not in st.session_state:
    st.session_state.df_text = pd.DataFrame()
if 'pdf_file' not in st.session_state:
    st.session_state.pdf_file = None
if 'data_file' not in st.session_state:
    st.session_state.data_file = None
if 'json_file' not in st.session_state:
    st.session_state.json_file = None
if 'api_key' not in st.session_state:
    st.session_state.api_key = ""
if 'height' not in st.session_state:
    st.session_state.height = ""
if 'symbol' not in st.session_state:
    st.session_state.symbol = ""
if 'height_map_str' not in st.session_state:
    st.session_state.height_map_str = ""
if 'height_map' not in st.session_state:
    st.session_state.height_map = {}
if 'user_input' not in st.session_state:
    st.session_state.user_input = ""
if 'task_completed' not in st.session_state:
    st.session_state.task_completed = False
if 'download_triggered' not in st.session_state:
    st.session_state.download_triggered = False
if 'total_input_tokens' not in st.session_state:
    st.session_state.total_input_tokens = 0
if 'total_output_tokens' not in st.session_state:
    st.session_state.total_output_tokens = 0

async def fetch_gpt_response(session, api_key, text, prompt):
    url = "https://api.openai.com/v1/chat/completions"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }
    payload = {
        "model": "gpt-4o-mini",
        "messages": [{"role": "user", "content": prompt.format(text)}]
    }
    async with session.post(url, headers=headers, json=payload) as response:
        return await response.json()

async def process_texts(api_key, texts, prompt, batch_size=10):
    async with aiohttp.ClientSession() as session:
        tasks = []
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            tasks.extend([fetch_gpt_response(session, api_key, text, prompt) for text in batch])
            if tasks:
                results = await asyncio.gather(*tasks)
                for result, text in zip(results, batch):
                    organized_text = result['choices'][0]['message']['content']
                    formatted_text = format_text(organized_text)
                    yield {"è²¨è™Ÿ": text, "æ–‡æ¡ˆ": formatted_text}

def search_and_zip_case1(file, texts, h, out_dir, zipf, api_key, prompt):
    total_files = len(texts)
    progress_bar = st.progress(0)
    progress_text = st.empty()
    progress_text.text("æº–å‚™è¼‰å…¥PDFèˆ‡CSVæ–‡ä»¶")

    for i, text in enumerate(texts):
        page_num, img_p = search_extract_img(file, text, out_dir, h=h)
        if img_p:
            zipf.write(img_p, os.path.basename(img_p))
        # æ›´æ–°é€²åº¦æ¢
        progress = (i + 1) / total_files
        progress_bar.progress(progress)
        progress_text.text(f"æ­£åœ¨æ“·å–åœ–ç‰‡: {text} ({i + 1}/{total_files})")
    progress_bar.empty()
    progress_text.empty()

# å®šç¾©æœå°‹å¤šå€‹æ–‡æœ¬ä¸¦å‰µå»ºå£“ç¸®æ–‡ä»¶çš„å‡½æ•¸ï¼Œæƒ…æ³2
def search_and_zip_case2(file, texts, symbol, height_map, out_dir, zipf):
    total_files = len(texts)
    progress_bar = st.progress(0)
    progress_text = st.empty()
    progress_text.text("æº–å‚™è¼‰å…¥PDFèˆ‡CSVæ–‡ä»¶")
    
    for i, text in enumerate(texts):
        res = search_pdf(file, text)
        if res:
            page_num, rect = res[0]
            doc = fitz.open(file)
            page = doc.load_page(page_num - 1)
            symbol_count = len(page.search_for(symbol))
            height = height_map.get(symbol_count, 240)
            img_p = extract_img(file, page_num, rect, out_dir, h=height, offset=-10)
            new_img_p = rename_img(img_p, f"{text}.png")
            zipf.write(new_img_p, os.path.basename(new_img_p))
        # æ›´æ–°é€²åº¦æ¢
        progress = (i + 1) / total_files
        progress_bar.progress(progress)
        progress_text.text(f"æ­£åœ¨æ“·å–åœ–ç‰‡: {text} ({i + 1}/{total_files})")
    progress_bar.empty()
    progress_text.empty()

def update_height():
    if st.session_state['height'] != st.session_state['height_input']:
        st.session_state['height'] = st.session_state['height_input']

def update_user_input():
    if st.session_state['user_input'] != st.session_state['user_input_input']:
        st.session_state['user_input'] = st.session_state['user_input_input']

def update_symbol():
    if st.session_state['symbol'] != st.session_state['symbol_input']:
        st.session_state['symbol'] = st.session_state['symbol_input']

def update_height_map_str():
    if st.session_state['height_map_str'] != st.session_state['height_map_str_input']:
        st.session_state['height_map_str'] = st.session_state['height_map_str_input']
        height_map = {}
        for item in st.session_state['height_map_str'].split("\n"):
            if ":" in item: 
                k, v = item.split(":")
                height_map[int(k.strip())] = int(v.strip())
        st.session_state['height_map'] = height_map

def main():
    create_directories() 
    
    with st.sidebar:
        st.image("Image/91APP_logo.png")
        selected = option_menu("",
        ["æ¯é å•†å“æ•¸å›ºå®š",'æ¯é å•†å“æ•¸ä¸å›ºå®š'],
        icons=['caret-right-fill','caret-right-fill'], menu_icon="robot", default_index=0,
        styles={
            "container": {"padding": "0!important", "background": "#F9F9F9","border-radius": "0px"},
            "icon": {"color": "#FF8C00", "font-size": "17px"},
            "nav-link": {"font-size": "17px","color": "#46474A", "text-align": "left", "margin":"2px", "--hover-color": "#D6EDF2"},
            "nav-link-selected": {"background": "#8EBDCD", "color": "#200"},
        }
    )
        with stylable_container(
            key="green_popover",
            css_styles="""
                button {
                    background: #46474A;
                    color: white;
                    border-radius: 8px;
                    border: none;
                    width: 100%;
                }
                """,
            ):
            st.divider()
            popover = st.popover("æ–‡ä»¶ä¸Šå‚³")
                 
        pdf_file = popover.file_uploader("ä¸Šå‚³å•†å“å‹éŒ„ PDF", type=["pdf"], key="pdf_file_uploader")
        data_file = popover.file_uploader("ä¸Šå‚³è²¨è™Ÿæª” CSV æˆ– XLSX", type=["csv", "xlsx"], key="data_file_uploader")
        json_file = popover.file_uploader("ä¸Šå‚³ Google Cloud æ†‘è­‰", type=["json"], key="json_file_uploader")
        st.write("\n")
        with stylable_container(
            key="text_input_styles",
            css_styles="""
                label {
                    color: #46474a;
                }
                """
            ):
            api_key = st.text_input("è¼¸å…¥ OpenAI API Key", type="password")

    # å°‡å·²ä¸Šå‚³çš„æ–‡ä»¶å­˜å…¥ session state
    if pdf_file:
        st.session_state.pdf_file = pdf_file
    if data_file:
        st.session_state.data_file = data_file
    if json_file:
        st.session_state.json_file = json_file
    if api_key:
        st.session_state.api_key = api_key

    # å¾ session state ä¸­ç²å–æ–‡ä»¶
    pdf_file = st.session_state.pdf_file
    data_file = st.session_state.data_file
    json_file = st.session_state.json_file
    api_key = st.session_state.api_key

    if json_file:
        temp_json_path = os.path.join("temp", json_file.name)
        with open(temp_json_path, "wb") as f:
            f.write(json_file.getbuffer())
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = temp_json_path

    if selected == "æ¯é å•†å“æ•¸å›ºå®š":
        height = st.text_input("æŒ‡å®šæˆªåœ–é«˜åº¦ (px)", placeholder="ä¾‹å¦‚ï¼š255", value=st.session_state.height, key='height_input', on_change=update_height, help="å¦‚ä½•æ‰¾åˆ°æˆªåœ–é«˜åº¦ï¼Ÿ\n\n1.æˆªä¸€å¼µæƒ³è¦çš„åœ–ç‰‡ç¯„åœ \n 2.ä¸Šå‚³Photoshopï¼ŒæŸ¥çœ‹å·¦å´çš„åœ–ç‰‡é«˜åº¦")
        user_input = st.text_area("çµ¦ ChatGPT çš„ Prompt", height=300, value=st.session_state.user_input, key='user_input_input', on_change=update_user_input)
    else:
        symbol = st.text_input("ç”¨ä¾†åˆ¤æ–·æˆªåœ–é«˜åº¦çš„ç¬¦è™Ÿæˆ–æ–‡å­—", placeholder="ä¾‹å¦‚ï¼š$", value=st.session_state.symbol, key='symbol_input', on_change=update_symbol)
        col1, col2 = st.columns([1,1.9])
        height_map_str = col1.text_area("å°æ‡‰çš„æˆªåœ–é«˜åº¦ï¼ˆpxï¼‰", placeholder="æ•¸é‡ï¼šé«˜åº¦ï¼ˆç”¨æ›è¡Œåˆ†éš”ï¼‰\n----------------------------------------\n2:350\n3:240", height=300, value=st.session_state.height_map_str, key='height_map_str_input', on_change=update_height_map_str, help="å¦‚ä½•æ‰¾åˆ°æˆªåœ–é«˜åº¦ï¼Ÿ\n\n1.æˆªä¸€å¼µæƒ³è¦çš„åœ–ç‰‡ç¯„åœ \n 2.ä¸Šå‚³Photoshopï¼ŒæŸ¥çœ‹å·¦å´çš„åœ–ç‰‡é«˜åº¦")
        user_input = col2.text_area("çµ¦ ChatGPT çš„ Prompt", height=300, value=st.session_state.user_input, key='user_input_input', on_change=update_user_input)
    
    def organize_text_with_gpt(text, api_key):
        client = OpenAI(api_key=api_key)
        prompt = f"'''{text} '''{st.session_state.user_input}"
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "user", "content": prompt}
            ],
        )
        
        # ä½¿ç”¨ tiktoken è¨ˆç®— tokens æ•¸é‡
        encoding = tiktoken.encoding_for_model("gpt-4")
        input_tokens = len(encoding.encode(prompt))
        output_tokens = len(encoding.encode(response.choices[0].message.content))
        
        # å°‡ tokens è¨ˆæ•¸å­˜å…¥ session_state
        st.session_state.total_input_tokens += input_tokens
        st.session_state.total_output_tokens += output_tokens
        
        return response.choices[0].message.content
    
    def check_required_fields():
        missing_fields = []
        if not pdf_file:
            missing_fields.append("PDF")
        if not data_file:
            missing_fields.append("CSV æˆ– XLSX")
        if not json_file:
            missing_fields.append("Google Cloud æ†‘è­‰")
        if not api_key:
            missing_fields.append("OpenAI API Key")
        if not st.session_state.user_input:
            missing_fields.append("çµ¦ ChatGPT çš„ Prompt")
        if selected == "æ¯é å•†å“æ•¸å›ºå®š" and not st.session_state.height:
            missing_fields.append("æŒ‡å®šæˆªåœ–é«˜åº¦")
        if selected == "æ¯é å•†å“æ•¸ä¸å›ºå®š":
            if not st.session_state.symbol:
                missing_fields.append("ç”¨ä¾†åˆ¤æ–·æˆªåœ–é«˜åº¦çš„ç¬¦è™Ÿæˆ–æ–‡å­—")
            if not st.session_state.height_map:
                missing_fields.append("å°æ‡‰çš„æˆªåœ–é«˜åº¦")
        return missing_fields
    
    # æª¢æŸ¥æ‰€æœ‰å¿…éœ€å­—æ®µæ˜¯å¦å·²å¡«å¯«
    missing_fields = check_required_fields()
    with stylable_container(
            key="run_btn",
            css_styles="""
                button {
                    background-color: #46474A;
                    color: white;
                    border-radius: 8px;
                    border: none;
                    width: 25%;
                }
                button:hover {
                    background: #6B6C70;
                }
                """,
            ):
        st.write("\n")
        start_running = st.button("é–‹å§‹åŸ·è¡Œ", key="run_btn")
    if start_running:
        if missing_fields:
            st.warning("è«‹ä¸Šå‚³æˆ–è¼¸å…¥ä»¥ä¸‹å¿…éœ€çš„é …ç›®ï¼š{}".format("ã€".join(missing_fields)))
        else:
            # é‡ç½®è¼¸å…¥å’Œè¼¸å‡º tokens è¨ˆæ•¸
            st.session_state.total_input_tokens = 0
            st.session_state.total_output_tokens = 0

            # æ¸…é™¤ä¹‹å‰çš„é¡¯ç¤ºå…§å®¹
            st.session_state.task_completed = False
            st.session_state.download_triggered = False
            st.session_state.zip_buffer = None
            st.session_state.zip_file_ready = False
            st.session_state.df_text = pd.DataFrame()

            temp_dir = "temp"
            output_dir = os.path.join(temp_dir, "output")
            clear_directory(output_dir)  

            pdf_path = os.path.join(temp_dir, pdf_file.name)
            with open(pdf_path, "wb") as f:
                f.write(pdf_file.getbuffer())

            data_path = os.path.join(temp_dir, data_file.name)
            with open(data_path, "wb") as f:
                f.write(data_file.getbuffer())

            try:
                if data_file.name.endswith('.csv'):
                    df = pd.read_csv(data_path, encoding='utf-8')
                else:
                    df = pd.read_excel(data_path, engine='openpyxl')
            except UnicodeDecodeError:
                if data_file.name.endswith('.csv'):
                    df = pd.read_csv(data_path, encoding='latin1')
                else:
                    df = pd.read_excel(data_path, engine='openpyxl')

            texts = df.iloc[:, 0].tolist()

            zip_buffer = io.BytesIO()
            with zipfile.ZipFile(zip_buffer, 'w') as zipf:
                if selected == "æ¯é å•†å“æ•¸å›ºå®š":
                    search_and_zip_case1(pdf_path, texts, int(st.session_state.height), output_dir, zipf, api_key, st.session_state.user_input)
                else:
                    search_and_zip_case2(pdf_path, texts, st.session_state.symbol, st.session_state.height_map, output_dir, zipf)

                image_files = [f for f in os.listdir(output_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]
                data = []
                total_files = len(image_files)

                progress_bar = st.progress(0)
                progress_text = st.empty()
                progress_text.text("æº–å‚™è¼‰å…¥æˆªåœ–")

                with concurrent.futures.ThreadPoolExecutor() as executor:
                    futures = {executor.submit(extract_text_from_image, os.path.join(output_dir, image_file)): image_file for image_file in image_files}
                    for future in concurrent.futures.as_completed(futures):
                        image_file = futures[future]
                        try:
                            text = future.result()
                            organized_text = organize_text_with_gpt(text, api_key)
                            formatted_text = format_text(organized_text)
                            data.append({"è²¨è™Ÿ": os.path.splitext(image_file)[0], "åœ–ç‰‡å…§å®¹": text, "æ–‡æ¡ˆ": formatted_text})
                        except Exception as exc:
                            print(f'{image_file} generated an exception: {exc}')

                        progress = len(data) / total_files
                        progress_bar.progress(progress)
                        progress_text.text(f"æ­£åœ¨æå–åœ–ç‰‡æ–‡å­—èˆ‡æ’°å¯«æ–‡æ¡ˆ: {image_file} ({len(data)}/{total_files})")

                progress_bar.empty()
                progress_text.empty()

                df_text = pd.DataFrame(data)
                csv_buffer = io.StringIO()
                df_text.to_csv(csv_buffer, index=False, encoding='utf-8-sig')  
                csv_data = csv_buffer.getvalue().encode('utf-8-sig')

                zipf.writestr("ocr_output.csv", csv_data)

            zip_buffer.seek(0)

            st.session_state.zip_buffer = zip_buffer.getvalue()
            st.session_state.zip_file_ready = True
            st.session_state.df_text = df_text
            st.session_state.task_completed = True

    if st.session_state.task_completed and st.session_state.zip_file_ready and not st.session_state.download_triggered:
        def usd_to_twd(usd_amount):
            result = convert(base='USD', amount=usd_amount, to=['TWD'])
            return result['TWD']

        input_cost = st.session_state.total_input_tokens / 1_000_000 * 0.15
        output_cost = st.session_state.total_output_tokens / 1_000_000 * 0.60
        total_cost_usd = input_cost + output_cost
        total_cost_twd = usd_to_twd(total_cost_usd)
            
        st.toast("åŸ·è¡Œå®Œæˆ ğŸ¥³ æª”æ¡ˆå·²è‡ªå‹•ä¸‹è¼‰è‡³æ‚¨çš„é›»è…¦")
        st.divider()
        col1,col2,col3 =st.columns(3)
        with col1:
            ui.metric_card(title="Input Tokens", content=f"{st.session_state.total_input_tokens} å€‹", description="US$0.15 / æ¯ç™¾è¬å€‹Tokens", key="card1")
        with col2:
            ui.metric_card(title="Output Tokens", content=f"{st.session_state.total_output_tokens} å€‹", description="US$0.60 / æ¯ç™¾è¬å€‹Tokens", key="card2")
        with col3:
            ui.metric_card(title="æœ¬æ¬¡åŸ·è¡Œè²»ç”¨", content=f"${total_cost_twd:.2f} NTD", description="æ ¹æ“šå³æ™‚åŒ¯ç‡", key="card3")
            
        with st.container(height=400,border=None):
            st.write("##### æˆæœé è¦½")
            ui.table(st.session_state.df_text)
        trigger_download(st.session_state.zip_buffer, "output.zip")
        st.session_state.download_triggered = True

if __name__ == "__main__":
    main()
